# 异步编程的难点
JavaScript异步代码很容易失控。匿名函数闭包和在位定义使我们拥有舒适的编程体验，不需要开发者跳到代码的其它部分。这和**KISS**原则是一致的；简单地说，它确。保了代码的流程，使开发时间变短。不幸的是，牺牲了模块化、可重用、可维护性等特性，会迟早导致回调堆叠的激增，函数代码量的增加，会导致较差的代码组织。大部分情况下，并不需要创建闭包，更多的是一个原则而不是为了解决异步编程的问题。意识到我们的代码正在变得笨重，好一点的情况，预先知道它可能会变得笨重，能否相应采取最好的解决方案是区别一个新手和老手的标识。
## 创建一个简单的网络爬虫
为了解释这个问题，我们将创建一个**网络爬虫**，一个命令行应用，接受URL作为输入然后下载其内容到本地文件中。在本章展示的代码中，我们将使用一些*npm*依赖：

* *request*:一个HTTP流的调用库。
* *mkdirp*:一个循环地创建目录的小工具。

同样，我们会经常引用一个本地模块，叫做*./utilities*,包含一些应用中将会用到的帮助模块。在书中我们简单地展示必要的部分，但你可以在本书的下载包（ https://www.packtpub.com/ ）中找到完整的实现，包括包含完整依赖列表的*package.json*文件。
应用的核心功能包含在一个叫做*spider.js*的模块中。让我们看下它是怎样的。首先，加载所有要使用的依赖：

```
var request = require('request');
var fs = require('fs');
var mkdirp = require('mkdirp');
var path = require('path');
var utilities = require('./utilities');
```
然后，我们创建一个新的函数，叫做*spider()*,接收要下载的URL和一个下载完后要被触发的回调函数：

```
function spider(url, callback) {
    var filename = utilities.urlToFilename(url);
    fs.exists(filename, function (exists) {//[1]
        if (!exists) {
            console.log('Downloading ' + url)
            request(url, function (err, response, body) {//[2]
                if (err) {
                    callback(err);
                } else {
                    mkdirp(path.dirname(filename), function (err) {//[3]
                        if (err) {
                            callback(err);
                        } else {
                            fs.writeFile(filename, body, function (err) {//[4]
                                if (err) {
                                    callback(err);
                                } else {
                                    callback(null, filename, true);
                                }
                            })
                        }
                    })
                }
            })
        } else {
            callback(null, filename, false);
        }
    })
}
```
前面的函数执行了如下任务：

1. 通过检查对应文件是否已经创建来检查URL是不是已经下载了：`fs.exists(filename, function (exists) ...`
2. 如果没找到文件，使用下面的代码下载URL：`request(url, function (err, response, body)...`。
3. 然后，确保文件所在的文件夹是否存在：`mkdirp(path.dirname(filename), function (err)...`
4. 最后，把HTTP响应的主体内容写入文件：`fs.writeFile(filename, body, function (err)...`

为了完成我们的网络爬虫应用，只需触发*spider()*函数来提供一个URL作为输入（在我们的例子中，从命令行参数读取它）：

```
spider(process.argv[2], function (err, filename, downloaded) {
    if (err) {
        console.log(err);
    } else if (downloaded) {
        console.log('Completed the download of "' + filename + '"')
    } else {
        console.log('"' + filename + '"was already downloaded')
    }
});
```
现在，我们可以试用一下我们的网络爬虫了，首先要确保项目文件夹中包含*utilities.js*模块和包含完整依赖列表的*package.json*文件。然后，通过运行如下命令安装所有的依赖：`npm install`。
下一步，我们可以执行*spider*模块来下载网页的内容，通过类似于下面的命令：`node spider http://www/example.com`。

> 我们的网络爬虫需要URL中包含协议（比如，*http://*）。同样，也不要指望被重定向的HTTP链接或者类似于图片的资源会被下载，这只是一个简单的案例，来表述异步编程是怎样的。

## 回调地狱
看我们前面定义的*spider()*方法，一定可以发现即使我们实现的算法非常简单，但还是导致了代码有好几层缩进，很难阅读。使用同步API实现一个类似的函数会显得比较直接，更不容易出错。然而，使用异步的CPS是另一种情形，滥用闭包会导致烂代码。
大量的闭包和在位回调定义导致代码变得不可读、不可控的情形叫做**回调地狱**。这是一个在Node.js和Javascript最著名的严重反模式。被这个问题影响的典型代码结构是：

```
asyncFoo(function(err) {
  asyncBar(function(err) {
    asyncFooBar(function(err) {
      [...]
    });
  });
});
```
我们可以看到，用这种形式写的代码形状和金字塔类似，是过深的嵌套导致的，这是它也被称为金字塔顶。
前面的问题最大的问题在于其可读性。由于嵌套太深，几乎不可能不能确定一个函数在哪结束的，另一个函数是在哪开始的。
另一个问题是由于不同作用域的变量名称重叠引起的。通常，我们需要使用类似的，甚至是同样的名字来描述变量的内容。最好的例子是指每个回调接收到的错误参数。
有些人尝试在使用同一个名字的变换来区分每个作用域中的对象，比如*err*、*err1*、*err2*等等；其他人更倾向于隐藏作用域中定义的变量，一直使用同一个名字；比如，*err*。两个可选项都不那么完美，会引起疑惑，增加引入缺陷的可能性。
同样地，我们必须记住，闭包在性能和内存使用上的开销非常低。除此之外，它们会产生内存泄露，非常不容易识别，因为我们都知道的，当前闭包的所有上下文都被垃圾回收机制保留。

> 一个非常好的介绍闭包在V8上的工作机制的文章是http://mrale.ph/blog/2012/09/23/grokking-v8-closures-for-fun.html ，作者是Vyacheslav Egorov，一个开发V8的谷歌工程师。

如果我们看*spider()*函数，将会发现它明显地表示了一个回调地狱的情况，有我们描述的所有问题。这正是我们要使用这章学到的模式和技术来解决的问题。

