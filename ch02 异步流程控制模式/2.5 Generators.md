# Generators
ES6规范引入了另一个机制，用于简化Node.js应用的异步流程控制。我们说的是**Generators**，也被称为半协程。它是子路径的生成器，可以有不同的入口。在一个普通的函数中，只能拥有一个入口，即触发函数本身。Generator和函数类似，但此外它可以挂起（使用**yield**声明），过一会之后还能恢复。在实现遍历器时Generator非常有用，这个可能会听起来耳熟，因为前面章节已经学到了怎样使用遍历器来实现非常有用的异步流程控制模式，诸如顺序执行和限制数量的并行执行。
> 在Node.js中，generator在0.11版本中就包含进来了，但在写作此书时，这个特性依旧不是默认开启的，需要带上`--harmony`或者`--harmony-generators`参数来使生成器正常工作。如果要尝试运行本节的例子，运行如下命令确保安装了正确版本的Node.js（0.11.0或以上版本）：`node --version`。

## 基础
在探索在异步流程控制中使用generator之前，很有必要学习一些基本概念。从语法部分开始；一个生成器函数的声明是在`function`后面加上`*`（星号）：

```
function* makeGenerator() {
    //body
}
```
在`makeGenerator()`方法内部，可以使用关键字`yield`来暂停执行，并把传入的值返回给调用者：

```
function* makeGenerator() {
    yield 'Hello World';
    console.log('Re-entered');
}
```
在前面的代码中，generator产出一个字符串`Hello World`并把函数的执行暂停。当generator恢复后，执行会从`console.log('Re-entered')`开始执行。
`makeGenerator()`函数其实是一个工厂，但它被触发后，返回一个新的生成器对象：

```
var gen = makeGenerator() ;
```
生成器对象最重要的方法是`next()`，它用于启动/恢复生成器的执行并返回一个对象，格式如下：

```
{
    value: <产出的值>,
    done: <如果执行到最后则为true>
}
```
这个对象包含生成器产出的值（`value`）和一个标识来说明生成器是否已经执行完毕（`done`）。

### 一个简单的例子
举个例子，创建一个新的模块*fruitGenerator.js*，代码如下：

```
function* fruitGenerator() {
    yield 'apple';
    yield 'orange';
    return 'watermelon';
}

var newFruitGenerator = fruitGenerator();
console.log(newFruitGenerator.next());    //[1]
console.log(newFruitGenerator.next());    //[2]
console.log(newFruitGenerator.next());    //[3]
```
使用如下命令运行新的模块：

```
node --harmony-generators fruitGenerator
```
前面的代码会打印如下输出：

```
{ value: 'apple', done: false }
{ value: 'orange', done: false }
{ value: 'watermelon', done: true }
```
以下是对上面的代码做出的解释：

1. 第一次`newFruitGenerator.next()`触发时，生成器开始执行，直到它到达第一个`yield`命令，它把生成器暂停并把值`apple`返回给了调用者。
2. 第二次触发`newFruitGenerator.next()`时，生成器恢复，从第二个`yeild`开始，按次序把执行再次暂停，同时把值`orange`返回给调用者。
3. 最后一次触发`newFruitGenerator.next()`使生成器从上次的位置开始恢复执行，`return`声明终结了生成器，返回值`watermelon`,并把结果中的`done`属性设置为`true`。
### 生成器作为遍历器
为更好地理解为什么生成器对于实现遍历器是多么有用，让我们来构建一个新的模块*iteratorGenerator.js*，写下如下代码：

```
function* iteratorGenerator(arr) {
    for (var i = 0; i < arr.length; i++) {
        yield arr[i];
    }
}

var iterator = iteratorGenerator(['apple', 'orange', 'watermelon']);
var currentItem = iterator.next();
while (!currentItem.done) {
    console.log(currentItem.value);
    currentItem = iterator.next();
}
```
使用如下命令运行代码：

```
node --harmony-generators iteratorGenerator
```
前面的程序会打印数组中的所有元素，结果如下：

```
apple
orange
watermelon
```
在这个例子中，每次调用`iterator.next()`，就会恢复生成器中的for循环，然后运行下一轮，产出数组的下一个元素。这个写法展示了怎样在多次调用之间保持生成器的状态。恢复之后，循环和所有的变量都和暂停之前一样。

### 传值给生成器
下面以学习怎样传值给生成器来结束对生成器基础功能的探索。这非常简单，只需要给`next()`提供一个参数，这个值在生成器内部将会作为`yeild`声明的返回值。
为展示这个特性，创建一个新的实例模块：

```
function* twoWayGenerator() {
    var what = yield null;
    console.log('hello ' + what);
}
var twoWay = twoWayGenerator();
twoWay.next();
twoWay.next('world');
```
当执行完毕后，前面的代码会打印`hello world`。其工作机制如下：

1. 当第一个`next()`方法被触发了，生成器到达了第一个`yield`函数，然后生成器被暂停了。
2. 当触发`next('world')`后，生成器从暂停中恢复，回到`yield`指令，但这次有一个值传回到生成器。这个值会接着赋给`what`变量。然后生成器执行`console.log()`指令并停止。

同样地，可以迫使生成器抛出一个异常。可以通过生成器的`throw`方法来实现，示例如下：

```
var twoWay = twoWayGenerator();
twoWay.next();
twoWay.throw( new Error() );
```
使用上面这个代码段，当`yield`函数返回时，`twoWayGenerator()`函数将会抛出一个异常。这和生成器内部抛出异常是类似的，这种异常可以和其它异常一样，可以被`try-catch`块捕获。

## 使用generator进行异步流程控制
你一定想知道生成器会如何帮助我们来处理异步操作。下面会举个例子，创建一个函数，使我们可以在生成器内部使用异步函数，然后当异步操作完成后，恢复生成器的执行。我们将这个函数称作`asyncFlow()`：

```
function asyncFlow(generatorFunction) {
    function callback(err) {
        if (err) {
            return generator.throw(err);
        }
        var results = [].slice.call(arguments, 1);
        generator.next(results.length > 1 ? results : results[0]);
    };
    var generator = generatorFunction(callback);
    generator.next();
}
```
前面的函数接收一个生成器作为输入，实例化它，然后立刻开始执行：

```
 var results = [].slice.call(arguments, 1);
generator.next(results.length > 1 ? results : results[0]);
```
`generatorFunction()`接收一个可以发生错误时触发`generator.throw()`回调作为输入；否则的话，它会通过把回调中拿到的结果传回的方式恢复执行：

```
if (err) {
    return generator.throw(err);
}
var results = [].slice.call(arguments, 1);
generator.next(results.length > 1 ? results : results[0]);
```
为展示这个简单函数的作用，创建一个新的模块`clone.js`,其功能是创建自身的副本，把刚刚创建的`asyncFlow()`函数代码粘贴进来，并附加下面的程序核心代码：

```
var fs = require('fs');
var path = require('path');

asyncFlow(function* (callback) {
    var fileName = path.basename(__filename);
    var myself = yield fs.readFile(fileName, 'utf8', callback);
    yield fs.writeFile('clone_of_' + fileName, myself, callback);
    console.log('Clone created');
});
```
很明显，在`asyncFlow()`函数的帮助下，使我们可以用线性的方式写异步代码，就和写同步阻塞代码一样！其背后的魔法应该已经清楚了。一旦异步操作完成，传递到每个异步函数的回调将会依次恢复生成器。这一切并不复杂，但效果非常好。
这项技术有两个变种，一种是和promise一起使用，另外一种是使用*thunks*(转换程序)。

> 用在基于生成器的流程控制中的转换程序只是一个函数，它给原始函数赋了除最回调函数以外的值。返回值是一个以回到函数作为参数的函数。比如，`fs.readFile()`转换后的版本如下：
 
```
function readFileThunk(filename, options) {
  return function(callback) {
    fs.readFile(filename, options, callback);
  }
}
```
不管是转换程序还是promise都使我们可以创建生成器，无需传入回调作为参数；比如，转换程序版本的`asyncFlow()`如下：

```
function asyncFlowWithThunks(generatorFunction) {
    function callback(err) {
        if (err) {
            return generator.throw(err);
        }
        var results = [].slice.call(arguments, 1);
        var thunk = generator.next(results.length > 1 ? results : results[0]).value;
        thunk && thunk(callback);
    };
    var generator = generatorFunction();
    var thunk = generator.next().value;
    thunk && thunk(callback);
}
```
技巧在于，读取`generator.next()`的返回值，它包含转换后的方法。下一步是触发转换后的程序本身，把前面定义的特殊回调函数注入。这样我们就可以以以下方式写代码了：

```
asyncFlowWithThunks(function* () {
    var myself = yield readFileThunk(__filename, 'utf8');
    yield writeFileThunk("clone of clone.js", myself);
    console.log("Clone created");
});
```
类似地，可以实现一个版本的`asyncFlow()`，接收一个promise作为可产出对象。我把这个留作练习，其实现只需小幅修改`asyncFlowWithThunks()`函数。也可以实现一个`asyncFlow()`函数，可以接收promise和转换后的函数作为可产出对象，使用相同的原则。

### 使用co进行基于generator的流程控制
你可能已经猜到了，Node.js生态系统已经提供了一些使用生成器处理异步流程控制的解决方案。比如，`suspend`(https://npmjs.org/package/suspend )就是其中比较古老的一个，支持promise、转换器、Node.js风格的回调还有原生的回调函数。同样地，大部分前面章节提到的promise库也提供了能让promise和生成器一起使用的帮助类。

所有这些解决方案和`asyncFlow()`函数基于相同的原理；所以我们可以利用他们中的一个，而不是自己写一个。

对于这一节的例子，选用*co*（ https://npmjs.org/package/co ），它现在正流行。作为一个弹性的解决方案，`co`支持一些类型的可产出对象，比如：

* 转换器
* Promise
* 数组（并行执行）
* 对象（并行执行）
* 生成器（委托）
* 生成器函数（委托）

`co`也有其代码库的生态系统，包括如下：

* web框架，最流行的是`koa`( https://npmjs.org/package/koa )
* 实现特定流程控制模式的库
* 包装流行API，使其支持*co*的库

后面将会使用*co*来实现生成器版本的网络爬虫。

其中，为了把Node.js风格的函数转换为转换器，将会使用一个小的类库叫做*thunkify*( https://npmjs.org/package/thunkify )。
## 顺序执行
以修改网路爬虫的第二个版本作为探索生成器和*co*的开始。要做的第一件事情是加载依赖，并生成一个转换器版本的函数以供使用。这些将对于*spider.js*做出修改：

```
var thunkify = require('thunkify');
var co = require('co');

var request = thunkify(require('request'));
var fs = require('fs');
var mkdirp = thunkify(require('mkdirp'));
var readFile = thunkify(fs.readFile);
var writeFile = thunkify(fs.writeFile);
var nextTick = thunkify(process.nextTick);
```
看上述代码，可以发现这和前面讲到的使API promise化的代码非常像。说到这里，一件非常有趣的事情是，如果我们想使用函数的promise化的版本替换转thunk版本，下面的代码依旧能够正常执行。这是因为*co*同时支持promise和chunk作为可产出对象。实际上，我们可以同时使用thunk和promise，即使在同一个生成器中。这在程序的灵活性方面有极大的优势，使我们可以使用基于生成器的流程控制，不管之前是哪种处理方式。

接下来，把`download()`函数转换为生成器：

```
function* download(url, filename) {
  console.log('Downloading ' + url);
  var results = yield request(url);
  var body = results[1];
  yield mkdirp(path.dirname(filename));
  yield writeFile(filename, body);
  console.log('Downloaded and saved:' + url);
  return body;
}
```
使用了生成器和*co*之后，  `download()`函数突然变得清晰了。只是把它转换为一个生成器函数，并在需要触发一个异步函数（是一个thunk）时使用`yield`。

接下来是`spider()`函数：

```
function* spider(url, nesting) {
    var filename = utilities.urlToFilename(url);
    var body;
    try {
        body = yield readFile(filename, 'utf8');
    } catch (err) {
        if (err.code !== 'ENOENT') {
            throw err;
        }
        body = yield download(url, filename);
    }
    yield spiderLinks(url, body, nesting);
}
```
从上段代码中可以发现一个有趣的细节是怎样使用`try-catch`模块来处理异常。同时，可以使用`throw`来传递错误！另外一个值得关注的点是`yield` `download()`函数的地方，它既不是一个thunk，也不是一个promise化的函数，只是另一个生成器。这样是可行的，多亏了`co`，它还支持其它生成器作为可产出对象。

最后，把`spiderLinks()`也做一下转换，在这个函数中，定义了一个遍历器来按顺序下载网页中的链接，使用生成器，这个函数也变得非常清晰：

```
function* spiderLinks(currentUrl, body, nesting) {
    if (nesting === 0) {
        return yield nextTick();
    }

    var links = utilities.getPageLinks(currentUrl, body);
    for (var i = 0; i < links.length; i++) {
        yield spider(links[i], nesting - 1);
    };
}
```
对于前面的代码，没什么好解释的，对于顺序执行，没什么模式需要说明；生成器和`co`把所有的脏活都干了，所以我们可以写异步的遍历，就跟写同步阻塞代码是一样的。

下面是最重要的部分，程序的入口：

```
co(function* () {
    try {
        yield spider(process.argv[2], 1);
        console.log('Download complete');
    } catch (err) {
        console.log(err);
    };
})();
```
这是唯一需要触发包装生成器的地方。事实上，一旦这样做，`co`会自动把任何传递给`yield`的生成器包装起来，而且是递归地执行的，剩下的程序完全不知道使用了`co`，即使他们都被它封装起来了。

> `co()`函数返回一个`thunk`，清楚地知道这一点是非常重要的。所以需要通过触发它来启动爬虫任务。

这样，我们可以运行这个基于生成器的爬虫程序了。记住要在命令中使用`--harmony`或者`--harmony-generators`参数：

```
node --harmony-generators spider <URL>
```
## 并行执行
关于生成器的坏消息是，虽然它在写顺序执行算法时非常棒，但不能用于并行执行一组任务，至少是不能只用`yield`和生成器。事实上，针对这种情况，基于回调或者是promise函数是非常简单的，然后他们可以被产出并未生成器所用。
幸运的是，对于这种无限并行执行的情况，`co`已经使我们可以简单地产出一组promise、thunk或生成器或者生成器函数。
顺着这个思路，网络爬虫版本3可以简单地通过重写`spiderLinks()`函数来实现：

```
function* spiderLinks(currentUrl, body, nesting) {
  if(nesting === 0) {
    return nextTick();
  }
  
  var links = utilities.getPageLinks(currentUrl, body);
  var tasks = links.map(function(link) {
    return spider(link, nesting - 1);
  });
  yield tasks;
}
```
上面的代码只是把所有的下载任务集合起来，他们其实都是生成器，然后然后再结果数组上产出。这些任务都会`co`并行地执行，然后当所有的任务执行完成后，生成器（`spiderLinks`）恢复执行。
如果你认为我发掘了`co`的特性才使我们可以产出一个数组，我也可以展示如何使用基于回调的解决方案来实现相同的并行流程，之前用到过类似的方式。现在用这个技术再次改写`spiderLinks()`：

```
function spiderLinks(currentUrl, body, nesting) {
  if(nesting === 0) {
    return nextTick();
  }
  
  //returns a thunk
  return function(callback) {
    var completed = 0, errored = false;
    var links = utilities.getPageLinks(currentUrl, body);
    if(links.length === 0) {
      return process.nextTick(callback);
    }
    
    function done(err, result) {
      if(err && !errored) {
        errored = true;
        callback(err);
      }
      if(++completed === links.length && !errored) {
        callback();
      }
    }
    
    for(var i = 0; i < links.length; i++) {
      co(spider(links[i], nesting - 1))(done);
    };
  }
}
```
为了并行地运行`spider()`函数，它是一个生成器，你需要把它转换为一个thunk并执行它。可以通过用`co(...)`函数来包裹它实现，这其实是在生成器外创建一个thunk。这样一来，你可以并行地触发它，并指定`done()`函数作为一个回调。通常，所有的基于生成器的流程控制库都有类似的特点，所以如果有需要的话，可以将生成器转换为基于回调的函数。
为了启动一个并行的多任务下载，我重用了基于回调的并行执行模式，在前面章节定义过。你同样可以发现，我把`spiderLinks()`函数转换成了一个thunk（它不再是生成器了）。它使我们在所有并行任务完成后拥有一个可以触发的`callback`函数。

> 模式（生成器到thunk）:把一个生成器转换为一个thunk，为了可以使其并行运行，或者为了利用其它流程控制算法（回调或者基于promise）的优势。
 

## 有限的并行执行
既然我们已经知道了怎样做才能使程序并行，那么就很容易实现网络爬虫的版本4，就是那个可以限制并发下载任务数的版本。有几个备选项可以实现这个功能：

* 使用本章前面提到的基于回调的版本中的`TaskQueue`类。我们只需把它的函数和所有的生成器都thunk化。
* 使用基于promise的`TaskQueue`类的版本，确保每个我们想用作任务的生成器都转换成返回promise的函数。
* 使用`async`，除了这个类库需要的生成器都转换为基于回调的函数之外，thunk化我们使用的所有帮助函数。
* 使用`co`生态系统的类库，特意为这种类型的流程设计，叫做`co-limiter`(http://npmjs.org/package/co-limiter ).
* 基于**生产者-消费者**模式实现一个自定义的算法，`co-limiter`也基于相同的内部机制。

出于教学目的，我们将选择最后一个选项，使我们可以深入一个经常和协程、线程、进程。

### 生产者消费者模式
目标是使用队列来保存一组固定的工作者，和我们设定的并发级别一样多。为实现这个算法，将从前面章节定义的`TaskQueue`类开始。我们一点一点地开始；定义构造器是第一件事情：

```
function TaskQueue(concurrency) {
  this.concurrency = concurrency;
  this.running = 0;
  this.taskQueue = [];
  this.consumerQueue = [];
  this.spawnWorkers(concurrency);
} 
```
注意`this.spawnWorkers()`的触发，这是负责启动工作者的方法。下一步是，定义工作者；下面是其代码：

```
TaskQueue.prototype.spawnWorkers = function(concurrency) {
  var self = this;
  for(var i = 0; i < concurrency; i++) {
    co(function* () {
      while(true) {
        var task = yield self.nextTask();
        yield task;
      }
    })();
  }
}
```
工作者的实现非常简单；他们只是用`co()`包装起来的生成器，立即执行，这样他们中的每一个都可以并行执行。在其内部，每个工作者运行一个无限循环，它等待队列中有新的任务可以执行（`yield self.nextTask()`），当触发了这个事件，它产出等待其完成的任务（它是可产出的）。你可能想知道，怎样等待队列中的下一个任务？答案在`nextTask()`方法中，我们将要定义这个方法：

```
TaskQueue.prototype.nextTask = function() {
  var self = this;
  return function(callback) {          //[1]
    if(self.taskQueue.length !== 0) {
      callback(null, self.taskQueue.shift());    //[2]
    } else {
      self.consumerQueue.push(callback);      //[3]
    }
  }
}
```
我们来看这个方法中发生了什么，这也是这个模式的核心:

1. 这个方法返回一个thunk，它对于`co`来说是可产出的。
2. 返回的thunk中的回调被触发，参数是taskQueue()中的下一个任务。这句代码会立即解锁工作者，提供下一个可产出的任务。
3. 如果队列中没有任务，回调本身被推到`consummerQueue`。这样一来，我们就把工作进程置于闲置状态。一旦有新的任务需要处理，`consumerQueue`函数中的回调就会被触发。它将恢复对应的工作者。

这样一来，就知道了`consumerQueue`函数中的闲置进程是怎样恢复的，下面将定义`pushTask()`方法：

```
TaskQueue.prototype.pushTask = function(task) {
  if(this.consumerQueue.length !== 0) {
    this.consumerQueue.shift()(null, task);
  } else {
    this.taskQueue.push(task);
  }
} 
```
很明显，如果有的话，该方法会触发`consumerQueue`函数中的第一个回调，它会按顺序解锁工作者。如果没有可用的回调，这意味着所有的工作者都很繁忙，所以我们简单地把它添加到`taskQueue`函数。
在我们刚定义的`TaskQueue`类中，工作者包含消费者的角色，所有使用`pushTask()`的对象可以被认为是一个生产者。这个模式告诉我们怎样使工作者看起来比较像一个线程（或者说是进程）。事实上，在学习内部进程通信技术时，生产者消费者交互可能是最常见的问题了，但我们已经提到过，这也是协程的一个常见用例。

### 限制下载任务的并发

既然已经使用生成器和生产消费模式实现了有限的并行算法，我们可以将其用于限制网络爬虫（版本4）的并发下载量。首先，初始化一个`TaskQueue`对象：

```
var TaskQueue = require('./taskQueue')
var downloadQueue = new TaskQueue(2)
```
下一步，修改`spiderLinks()`函数。其主体和刚刚用来实现无限并行执行流程的版本类似，下面只展示变化的部分：

```
function spiderLinks(currentUrl, body, nesting) {
  [...]
  return function(callback) {
    [...]
    function done(err, result) {
      [...]
    }
    links.forEach(function(link) {
      downloadQueue.pushTask(function *() {
        yield spider(link, nesting - 1);
        done();
      });
    });
  }
} 
```
在每个任务中，当下载完成后会触发`done()`函数，所以可以数出有多少链接被下载了，然后当所有的任务都完成后，通知thunk的回调。
作为一个练习，你可以用本节提到另外四种方法试着实现网络爬虫的版本4。

