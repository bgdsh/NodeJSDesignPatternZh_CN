# 复制与负载均衡
当分配给一台机器的资源无法再升级或者升级带来的成本上升高于简单地开启另一台服务器时，传统的多线程服务器就需要拓展了。通过使用多线程，传统的服务器能够充分利用服务器的所有处理能力，使用所有的处理器和系统。然而，一个单独的Node.js线程无法实现这个功能，因为它是单线程的并且有一个1GB的限制（在64位的机器上，可以增加到1.7GB )。这意味着Node.js应用相对于传统服务器需要更经常地拓展，即便是在单机情况下，也需要能够充分利用所有的资源。

> 在Node.js中，**竖向拓展**（为单台机器增加更多的资源）和**横向拓展**（为基础设施增加更多的机器）基本是等同的概念；都是引入相同的技术来充分利用所有的处理能力。

不要傻傻地认为这是一个劣势。相反，几近于强制的拓展在某些方面是对程序有利的，尤其是在可用性和容错方面。事实上，通过复制的方式来拓展Node.js应用是相对来说比较简单的，并且即便是没必要使用更多资源的时候，只是为了拥有冗余和容错能力。
这也迫使开发者从应用早期就考虑拓展性，确保应用不依赖任何不能跨进程、机器的资源。事实上，预先考虑的可拓展性是指每个实例都不存储不能共享的通用信息，通常是指硬件，诸如内存和磁盘。比如，在web服务器上，把会话存储在磁盘上不利于拓展；相反，使用一个共享的数据库能够确保每个实例都能访问相同的绘画信息，不管它部署在哪。
现在来介绍最基础的拓展Node.js的机制：*cluster*模块。

## 集群模块
在Node.js中，在单台机器上的不同实例间分配负载的最简单模式是使用*cluster*模块，它是核心库的一部分。*cluster*模块简化了建立同一应用的一个新实例的工作，在它们中间自动地分配链接，如下图所示：

![](../images/cluster-module.png)

**主进程**负责管理一系列的进程（**workers**），每个都代表你想拓展的实例。每个进入的链接然后被分配到被复制的worker,在他们中分配他们。

### 关于集群模块的行为备注
在Node.js的0.8和0.10中，*cluster*模块使所有的worker都共享相同的服务器链接，把在多个worker间**负载均衡**的工作留给操作系统。然而，这种方式有个问题；事实上，操作系统在worker之间分配负载的算法不是用来做网络请求的负载均衡的，而是安排线程的执行。这样一来，实例之间的分配就不均衡了；经常是一部分worker接收了大部分的负载。这种行为对于操作系统调度器是有意义的，因为它专注于把不同进程间的上下文切换减到最低。这是*cluster*模块在Node.js低于0.10版时无法发挥最大可能性的原因。
然而，从0.11.2开始情况变化了，简明的**单循环**负载均衡算法被加入到主线程中，确保了请求均衡地分配到所有的worker上。新的负载均衡算法在除了Windows之外的所有平台默认开启，可以通过全局设置*cluster.schedulingPolicy*变量来修改，使用常量*cluster.SCHED_RR*（单循环算法）或*cluster.SCHED_NONE*（操作系统处理）。

>单循环算法基于轮转平等地分发负载。第一个请求指向第一个服务，第二个指向列表的下一个，以此类推。当到达列表末尾时，循环又重新开始。这是最简单最常用的负载均衡算法之一；然而，这不是唯一的。更高级的算法允许置顶优先级，选择负载最小或者响应最快的服务。

> 你可以在下面的两个issue中找到*cluster*模块演进的细节：
> 
> * https://github.com/joyent/node/issues/3241
> * https://github.com/joyent/node/issues/3241

### 构建一个简单的HTTP服务器
现在开始创建一个实例，构建一个小的HTTP服务器，使用*cluster*模块进行复制和负载均衡。首先，需要应用可拓展；对这个例子来说，不需要太多，只是一个基本的HTTP服务器。
然我们创建一个叫做*app.js*的文件，包含如下代码：

```
var http = require('http');
var pid = process.pid;

http.createServer(function(req, res) {
  for(var i = 1e7; i > 0; i--) {}
  console.log('Handling request from ' + pid);
  res.end('Hello from ' + pid + '\n');
}).listen(8080, function() {
  console.log('Started ' + pid);
}); 
```
我们构建的这个HTTP服务对于任何请求都返回一条包含PID的消息；这样对于确定应用的那个实例处理的这个请求。同样的，来模拟真实的CPU事务，我们运行一个空的循环1000万次；没有这个，在小规模的测试时，将什么都感觉不到。

> 我们想要拓展的*app*模块可以是任何东西，也可以是使用web框架实现的，比如*express*。

我们现在检查是不是所有的实例都按预期运行，可以想平常一样运行应用，使用浏览器或者*curl*发送请求。
我们也可以来测量使用一个线程每秒能处理的请求数，我们可以使用网络测试工具来达到这个目的，比如**[siege](http://www.joedog.org/siege-home)**或Apache [ab](http://httpd.apache.org/docs/2.4/programs/ab.html)

```
siege -c 200 -t 10S http://localhost:8080”
```
使用*ab*，命令行如下：

```
ab -c 200 -t 10 http://localhost:8080/
```
前面的命令将在10秒之内请求200次。作为参考，四个处理器的系统每秒大约能处理90个事务，每个CPU的使用率只有20%。

> 请记住，我们在这一章运行的负载测试是有意的简单、最小化，用于参考和学习目的。其结果并不能为我们分析的各种技术提供一个100%准确的评估。


### 使用cluster模块进行拓展
现在我们试着使用*cluster*模块拓展我们的应用，让我们创建一个新的模块，叫做*clusterApp.js*:

```
var cluster = require('cluster');
var os = require('os');

if(cluster.isMaster) {
  var cpus = os.cpus().length;
  //start as many children as the number of CPUs
  for (var i = 0; i < cpus; i++) {      //[1]
    cluster.fork();
  }
} else {
  require('./app');           //[2]
}
```
由此可见，使用*cluster*需要很少的工作。让我们来分析一下发生了什么：

1. 当我们在命令行启动*clusteredApp*时，我们执行的是主线程。*cluster.isMaster*变量设置为*true*，我们要做的只有使用*cluster.fork()*复制当前的进程。在前面的例子中，我们开启了和CPU数量一样多的进程，来利用所有的计算能力。
2. 当*cluster.fork()*在主进程被执行，当前的主模块（*clusteredApp*）又运行了一遍，这次是worker模式（*cluster.isWorker*被设置为false）。当程序作为worker运行时，可以执行一些特定的工作。在我们的例子中，我们加载了*app*模块，启动了一个新的HTTP服务。

> 记住每个worker是一个不同的Node.js进程，有自己的事件循环、内存空间、加载的模块。

需要清楚，*cluster*模块的使用是基于递归模式的，非常容易运行一个应用的多个实例：

```
if(cluster.isMaster) {
	// fork()
} else {
	// do work
}
```
> 在罩子下，*cluster*模块使用*child_process.fork()*API（我们已经在第六章 模式菜谱 中见过），同时，主从之间也有一个沟通的渠道。worker的实例可以通过*cluster.workers*变量访问，所以给所有的进程发布一条信息将会非常简单，使用如下代码：
> 
> ```
> Object.keys(cluster.workers).forEach(function(id) {
  cluster.workers[id].send('Hello from the master');
}); 
> ```

现在，我们尝试以集群模式运行我们的HTTP服务器。我们可以像往常一样启动*clusteredApp*模块：

```
node clusteredApp
```
如果我们的及其拥有多于一个的处理器，我们可以看到一些worker被主进程启动起来了。比如，在一个拥有4个处理器的系统中，终端看起来应该是这样的：

```
Started 14107
Started 14108
Started 14109
Started 14110
```
如果我们再试着通过URL `http://localhost:8080`访问我们的服务器，可以发现每个请求都返回一个包含不同PID的信息，这意味着这些请求已经被不同的工作进程处理了，确定了负载是在他们之间分布的。
现在，我们可以再次试着加载我们的服务器：

```
siege -c 200 -t 10S http://localhost:8080
```
这样，我们可以发现在不同的处理器中间拓展应用使其性能增加了。作为参考，在拥有4个处理器的Linux系统，使用Node.js 0.10 ，性能大概增加了3倍（270 处理/秒 比 90处理/秒），CPU平均负载90%。

### 集群模式的弹性和可用性

### 零停机时间重启

## 处理状态沟通

### 多实例共享状态

### 棘手的负载均衡

## 通过反向代理拓展

### 使用Nginx实现负载均衡

## 使用服务注册

### 使用http-proxy和seaport实现动态负载均衡

## 点到点的负载均衡

### 实现一个可以平衡多台服务器请求的HTTP客户端



