# 使用流进行异步流程控制
看过这么多的例子，大家应该已经非常清楚了流不光可以用于处理I/O，而且是一种用于处理任何种类数据的编程模式。但是其优势不光体现在表面；流也可以用于把异步控制流转变为流程控制，本节将讨论这些内容。
## 顺序执行
默认情况下，流会按顺序处理数据，比如，在前一次调用完成并执行`callback()`之前，`Transform`的`_transform()`方法不会执行来处理下一块数据。这是流的一个重要特性，是以正确的顺序处理每一块数据的关键，但这也可以被发掘用于把流转换为一种优雅的流程控制解决方案。

代码比过多的解释更能说明问题，那么接下来就展示一个例子，来展示如何使用流来按顺序执行异步任务。现在创建一个函数，连接输入的一组文件，并确保其顺序和给定的顺序一致。创建一个新的模块`concatFiles.js`并从其依赖开始定义其内容：

```
var fromArray = require('from2-array');
var through = require('through2');
var fs = require('fs');
```
我们将使用`through2`来简化`Transform`流的创建，使用`from2-array`从一组对象创建一个可读流。

接下来，我们可以定义`concatFiles()`函数：

```
function concatFiles(destination, files, callback) {
  var destStream = fs.createWriteStream(destination);
  
  fromArray.obj(files)             //[1]
    .pipe(through.obj(function(file, enc, done) {   //[2]
      var src = fs.createReadStream(file);
      src.pipe(destStream, {end: false});
      src.on('end', function() {         //[3]
        done();
      });
    }))
    .on('finish', function() {         //[4]
      destStream.end();
      callback();
    });
}
module.exports = concatFiles;
```
前面的函数实现了对`files`数组按顺序遍历，并将其转换到一个流中。下面是对这个过程的解释：

1. 首先，使用`from2-array`来从`files`数组创建一个`Readable`流。
2. 接下来，我们创建一个*through*（`Transform`）流，来处理队列中的每个文件。对于每个文件，创建一个`Readable`流，然后将其导入到`destStream`，它代表输出到的文件。我们需要确保读取完成后不关闭`destStream`，通过指定`pipe()`的`{end:false}`选项。
3. 当源文件的所有内容都被导入到`destStream`，我们触发`done()`，触发对下一个文件的处理。
4. 当所有的`files`都被处理之后，会触发`finish`事件；
## 无序的并行执行

### 实现无序并行流

### 实现一个URL状态监控程序

## 有限的无序并行执行

### 有序的并行执行


